#type:     node
#context:  sop
#internal: labs::ml_cv_rop_annotation_output::1.0
#icon:     /labs_icons/sidefxlabs_default.svg
#since:    20.5

= Labs ML CV ROP Annotation Output =

"""Outputs a ground truth JSON per frame and then aggregates them all into a COCO JSON file for the full dataset."""


This node takes a scene with all its Metadata, Labels, and Synth Attributes and outputs a ground truth JSON per frame, then aggregates the per frame JSON files into a single [COCO JSON|https://cocodataset.org/#home] file for the full dataset.

WARNING:
    Compute keypoint visibility can be inconsistent if the points are on top of each other.

:box:
    #display: raised yellow

    The original ML Computer Vision tools were developed by the Synthetic Data team at Endava PLC.


@parameters

    == General ==

    Partition By:
        #id: partitionby
        Uses Connectivity to loop through objects to generate JSON.
        
        Piece:
            
        3D Connectivity:
            
    Piece Elements:
        #id: class
        Specifies the class of attribute to use for defining pieces in the `for each` loop within this node.
        
        Primitives:
            
        Points:
            
    Piece Attribute:
        #id: pieceattr
        Specifies the name of the attribute to use for defining pieces in the `for each` loop within this node.
        
    Visualize IDs:
        #id: visid
        Toggles random color assignment to visualize the assignment of IDs.
        
    Visualize:
        #id: vis
        Changes between visualizing Instance IDs or Category IDs.
        
    Dome Camera LOP Path:
        #id: loppath
        Specifies the Houdini path to the LOP node from which the camera primitive is retrieved.
        
    Camera Primitive:
        #id: primpath
        Specifies the USD primitive path pointing to the camera (used to get screen space).
        
    Compute Object Screen Percentage:
        #id: compvis
        Enables ground truth defining what percentage of each object is visible to the camera.
        
    Resolution Multiplier:
        #id: resmult
        Adjusts the precision level for calculating the Visibility Percentage
        
    Visualize Object Screen Percentage:
        #id: visobjscreenpct
        Previews the calculation of visibility percentage
        
    Use VDB Keypoint Visibility:
        #id: usevdb
        Converts objects to VDB before calculating visibility. This is sometimes useful for closely layered objects.
        
    === Pack Geometry ===

    Group:
        #id: group
        A subset of points in the input geometry to run the program on. Leave this blank to affect all points in the input.
        
    Group Type:
        #id: grouptype
        What the group is made of (point, vertex, primitive etc).
        
        Guess from Group:
            
        Breakpoints:
            
        Edges:
            
        Points:
            
        Primitives:
            
    Delete Unused Groups:
        #id: removegrp
        Deletes any geometry that does not belong to a group listed above.
        
    === Output Attributes ===

    Auto Add Existing Synth Attributes:
        #id: attrfrominput
        Finds existing synth attributes in the scene geometry and build a multiparm element for each one.

    Synth Attributes:
        #id: synthattr
        The number of synthetic attributes.
        
    === Synth Attributes ===

    Synth Attribute:
        #id: synthattr#
        Name of the synth attribute to be exported to COCO JSON.
        
    == PDG ==

    Export JSON:
        #id: execute
        Exports the ground truth JSON for the active frame/work item. This button is generally executed using a ROP Fetch in a `ROP Synthetic Data TOP` node.
        
    Aggregate JSON:
        #id: aggregate
        Consolidates all individual frame JSON files into a single COCO JSON file for the entire dataset. This button is generally executed using a ROP Fetch in a `ROP Synthetic Data TOP` node.
        
    Frame Number:
        #id: framenum
        The number of the current frame. defaults to `@frame_index`, an attribute created by the ROP Synthetic Data  TOP.
        
    Camera Resolution:
        #id: camres
        Specifies the camera resolution. Defaults to @res, a PDG attribute created by the ROP Synthetic Data TOP.
        
    Output Path:
        #id: outputpath
        Specifies the location of the dataset directory. By default, this calls an attribute created by the `ROP Synthetic Data` TOP node.
        
    Filename:
        #id: filename
        Path and filename pattern specifying where per dataset frames should be rendered and what they should be named.
        
    JSON Path:
        #id: fullpath
        Path and filename pattern specifying where per image JSONs should be generated and what they should be named.
        
    COCO Path:
        #id: aggpath
        Path and filename pattern specifying the location where the aggregated [COCO JSON|https://cocodataset.org/#home] file for the dataset should be generated and what it should be named.
    

@examples

    TIP:
        When viewing in Houdini's Help Browser, please copy the example file's URL to a regular browser to proceed with the download.

    - [Example File|https://github.com/sideeffects/SideFXLabsExamples/blob/main/examples/ml_computer_vision/ml_computer_vision.1.0.zip]


@related